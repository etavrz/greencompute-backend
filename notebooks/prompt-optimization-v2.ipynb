{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dspy\n",
    "from dspy.evaluate import SemanticF1\n",
    "import json\n",
    "import requests\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to setup datset and evaluation\n",
    "def create_dataset(path: str) -> list[dspy.Example]:\n",
    "\tdataset = pd.read_excel(path)\n",
    "\tdataset_dict = dataset.to_dict(orient='records')\n",
    "\tdspy_dataset = []\n",
    "\n",
    "\tfor row in dataset_dict:\n",
    "\t\tdspy_dataset.append(dspy.Example(question=row['input'], response=row['expected_output']).with_inputs(\"question\"))\n",
    "\n",
    "\tprint(f\"Dataset length: {len(dspy_dataset)}\")\n",
    "\treturn dspy_dataset\n",
    "\n",
    "def create_sets(dataset: list[dspy.Example], metric: dspy.Module = SemanticF1()):\n",
    "\ttrainset, valset, devset, testset = dataset[:15], dataset[15:30], dataset[30:40], dataset[40:]\n",
    "\tevaluate = dspy.Evaluate(devset=devset, metric=metric, num_threads=24, display_progress=True, display_table=3)\n",
    "\n",
    "\tfor name, set in zip([trainset, valset, devset, testset], [\"trainset\", \"valset\", \"devset\", \"testset\"]):\n",
    "\t\tprint(f\"{set} length: {len(name)}\")\n",
    "\n",
    "\treturn trainset, valset, devset, testset, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 52\n",
      "trainset length: 15\n",
      "valset length: 15\n",
      "devset length: 10\n",
      "testset length: 12\n"
     ]
    }
   ],
   "source": [
    "dspy_dataset = create_dataset(\"synthetics/synthetic_dataset_revised.xlsx\")\n",
    "trainset, valset, devset, testset, evaluate = create_sets(dspy_dataset)\n",
    "\n",
    "# Save the testset to a file\n",
    "with open(\"testset.json\", \"w\") as f:\n",
    "\tjson.dump([example.toDict() for example in testset], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, top_k: int) -> list[str]:\n",
    "    url = \"http://greencompute-1575332443.us-east-1.elb.amazonaws.com/api/llm/retrieval\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"query\": query,\n",
    "        \"top_k\": top_k\n",
    "    }\n",
    "\n",
    "    documents = requests.post(url, headers=headers, json=data).json()[\"documents\"]\n",
    "    return [f\"[{i}]\" + doc[\"doc_title\"] + doc[\"url\"] + \"\\n\\n\" + doc[\"content\"] for i, doc in enumerate(documents)]\n",
    "\n",
    "class TitanLM(dspy.LM):\n",
    "    def __init__(self, model: str, client, max_tokens: int = 1024, temperature: float = 0.3, top_p: float = 0.7, **kwargs):\n",
    "        self.client = client\n",
    "        self.history = []\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = 1024\n",
    "        self.top_p = top_p\n",
    "\n",
    "        super().__init__(model, **kwargs)\n",
    "        self.model = model\n",
    "    \n",
    "    def _format_message(self, prompt: str):\n",
    "        body = json.dumps(\n",
    "            {\n",
    "                \"inputText\": prompt,\n",
    "                \"textGenerationConfig\": {\n",
    "                    \"maxTokenCount\": self.max_tokens,\n",
    "                    \"stopSequences\": [],\n",
    "                    \"temperature\": self.temperature,\n",
    "                    \"topP\": self.top_p,\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "        return body\n",
    "\n",
    "    def generate_content(self, prompt: str) -> str:\n",
    "        body = self._format_message(prompt)\n",
    "        response = self.client.invoke_model(\n",
    "            body=body,\n",
    "            modelId=self.model,\n",
    "            accept=\"application/json\",\n",
    "            contentType=\"application/json\",\n",
    "        )\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "        return response_body.get(\"results\")\n",
    "\n",
    "    def __call__(self, prompt=None, messages=None, **kwargs):\n",
    "        # Custom chat model working for text completion model\n",
    "        prompt = '\\n\\n'.join([x['content'] for x in messages] + ['BEGIN RESPONSE:'])\n",
    "\n",
    "        completions = self.generate_content(prompt)\n",
    "        self.history.append({\"prompt\": prompt, \"completions\": completions})\n",
    "\n",
    "        # Must return a list of strings\n",
    "        return [completions[0].get(\"outputText\")]\n",
    "\n",
    "    def inspect_history(self):\n",
    "        for interaction in self.history:\n",
    "            print(f\"Prompt: {interaction['prompt']} -> Completions: {interaction['completions']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_docs=20):\n",
    "        self.num_docs = num_docs\n",
    "        self.respond = dspy.ChainOfThought('context, question -> response')\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = search(question, top_k=self.num_docs)\n",
    "        return self.respond(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = TitanLM(\"amazon.titan-text-premier-v1:0\", client=boto3.client(\"bedrock-runtime\"))\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The question is asking for ways to increase data center efficiency. The document \"Small Data Centers, Big Energy Savings\" provides tips for increasing data center efficiency.',\n",
       "    response='To increase your data center efficiency, consider the following tips:\\n1. Optimize your server utilization.\\n2. Use energy-efficient equipment.\\n3. Implement a data center infrastructure management (DCIM) system.\\n4. Utilize a high-efficiency UPS system.\\n5. Implement a cooling system that is optimized for your data center.'\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag = RAG()\n",
    "rag(question=\"How do I increase my data center efficiency?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.333333333333333 / 10  (13.3): 100%|██████████| 10/10 [00:19<00:00,  1.98s/it]\n",
      "2024/11/20 19:47:41 INFO dspy.evaluate.evaluate: Average Metric: 1.333333333333333 / 10 (13.3%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e38b1 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e38b1 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e38b1_row0_col0, #T_e38b1_row0_col1, #T_e38b1_row0_col2, #T_e38b1_row0_col3, #T_e38b1_row0_col4, #T_e38b1_row1_col0, #T_e38b1_row1_col1, #T_e38b1_row1_col2, #T_e38b1_row1_col3, #T_e38b1_row1_col4, #T_e38b1_row2_col0, #T_e38b1_row2_col1, #T_e38b1_row2_col2, #T_e38b1_row2_col3, #T_e38b1_row2_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e38b1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e38b1_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_e38b1_level0_col1\" class=\"col_heading level0 col1\" >example_response</th>\n",
       "      <th id=\"T_e38b1_level0_col2\" class=\"col_heading level0 col2\" >reasoning</th>\n",
       "      <th id=\"T_e38b1_level0_col3\" class=\"col_heading level0 col3\" >pred_response</th>\n",
       "      <th id=\"T_e38b1_level0_col4\" class=\"col_heading level0 col4\" >SemanticF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e38b1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e38b1_row0_col0\" class=\"data row0 col0\" >What factors, including multi-tenancy and operator incentives, contribute to cloud's lower environmental impact?</td>\n",
       "      <td id=\"T_e38b1_row0_col1\" class=\"data row0 col1\" >Cloud services generally have a lower environmental impact due to several key factors: 1. **Multi-tenancy**: This concept allows multiple customers to share resources, leading to...</td>\n",
       "      <td id=\"T_e38b1_row0_col2\" class=\"data row0 col2\" >The context does not mention anything about cloud's lower environmental impact.</td>\n",
       "      <td id=\"T_e38b1_row0_col3\" class=\"data row0 col3\" >I cannot answer this question based on the given context.</td>\n",
       "      <td id=\"T_e38b1_row0_col4\" class=\"data row0 col4\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e38b1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e38b1_row1_col0\" class=\"data row1 col0\" >Identify how virtualization, power management, and cloud computing reduce energy waste and enhance business operations in server rooms.</td>\n",
       "      <td id=\"T_e38b1_row1_col1\" class=\"data row1 col1\" >Virtualization reduces energy waste in server rooms by allowing multiple virtual machines to run on a single physical server, optimizing hardware usage and decreasing the...</td>\n",
       "      <td id=\"T_e38b1_row1_col2\" class=\"data row1 col2\" >I cannot find sufficient information to answer the question.</td>\n",
       "      <td id=\"T_e38b1_row1_col3\" class=\"data row1 col3\" >Sorry, I cannot find sufficient information to answer the question.</td>\n",
       "      <td id=\"T_e38b1_row1_col4\" class=\"data row1 col4\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e38b1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e38b1_row2_col0\" class=\"data row2 col0\" >How do virtualization and cloud computing synergistically enhance server room energy efficiency and utilization rates?</td>\n",
       "      <td id=\"T_e38b1_row2_col1\" class=\"data row2 col1\" >Virtualization and cloud computing work together to significantly enhance server room energy efficiency and utilization rates by improving resource allocation and reducing energy consumption. Virtualization...</td>\n",
       "      <td id=\"T_e38b1_row2_col2\" class=\"data row2 col2\" >I cannot find sufficient information to answer the question.</td>\n",
       "      <td id=\"T_e38b1_row2_col3\" class=\"data row2 col3\" >Sorry, I cannot find sufficient information to answer the question.</td>\n",
       "      <td id=\"T_e38b1_row2_col4\" class=\"data row2 col4\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x167813410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 7 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "13.33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(RAG())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/20 19:48:45 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING MEDIUM AUTO RUN SETTINGS:\n",
      "num_trials: 25\n",
      "minibatch: False\n",
      "num_candidates: 19\n",
      "valset size: 15\n",
      "\n",
      "2024/11/20 19:48:45 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2024/11/20 19:48:45 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2024/11/20 19:48:45 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=19 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/19\n",
      "Bootstrapping set 2/19\n",
      "Bootstrapping set 3/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [02:37<00:24, 12.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 13 examples for up to 1 rounds, amounting to 13 attempts.\n",
      "Bootstrapping set 4/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:11<02:36, 11.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 5/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:16<03:52, 16.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 6/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:37<02:30, 12.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 7/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [01:26<02:53, 17.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 8/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:13<03:15, 13.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 9/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:34<02:16, 11.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 10/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [01:25<00:56,  9.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 9 examples for up to 1 rounds, amounting to 9 attempts.\n",
      "Bootstrapping set 11/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:21<02:21, 10.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 12/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:11<02:38, 11.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 13/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [01:46<01:11, 11.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 9 examples for up to 1 rounds, amounting to 9 attempts.\n",
      "Bootstrapping set 14/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [01:23<00:55,  9.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 9 examples for up to 1 rounds, amounting to 9 attempts.\n",
      "Bootstrapping set 15/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:30<03:16, 15.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 16/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [01:10<01:45, 11.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "Bootstrapping set 17/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [01:01<01:32, 10.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "Bootstrapping set 18/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:35<03:51, 17.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 19/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:22<01:28,  7.33s/it]\n",
      "2024/11/20 20:03:31 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2024/11/20 20:03:31 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/20 20:03:44 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing instructions...\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Given the fields `context`, `question`, produce the fields `response`.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Given the fields `context`, `question`, produce the fields `reasoning`, `response`.\n",
      "\n",
      "1. Use the search function to find relevant context for the given question.\n",
      "2. Use the ChainOfThought module to generate a reasoning and response based on the context.\n",
      "3. Return the reasoning and response.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are a data center manager. You are looking for ways to improve the energy efficiency of your data center. You want to know how variable-speed chillers can enhance efficiency by adapting to changing cooling load conditions.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Given the fields `context`, `question`, produce the fields `reasoning`, `response`.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 4: Given the fields `context`, `question`, produce the fields `response`.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 5: You are a data center manager tasked with reducing energy consumption in a small server room with varied configurations. You have access to a dataset on energy efficiency in server rooms and data centers. Your goal is to use this dataset to identify energy-saving measures that can optimize efficiency in your server room.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 6: Analyze the energy efficiency of rack-level cooling systems versus traditional cooling methods in server environments.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 7: Analyze the energy efficiency of rack-level cooling systems versus traditional cooling methods in server environments.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 8: How does upgrading IT equipment impact energy cost savings?\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 9: How do variable-speed chillers enhance efficiency by adapting to changing cooling load conditions in data centers?\n",
      "A: Variable-speed chillers enhance efficiency in data centers by adapting to changing cooling load conditions through the use of variable-speed drives (VSDs) that control the speed of the chiller's compressor. By adjusting the compressor speed, these chillers can match the cooling output to the actual demand, reducing energy waste and improving overall efficiency.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 10: You are a data analyst for a large tech company that operates multiple data centers around the world. Your job is to estimate the energy savings for specific data center improvements. You have been given a list of primary systems, each with a description, estimated impact, estimated cost for implementation, simple payback, and time horizon. Your task is to calculate the total estimated impact, total estimated cost for implementation, and total simple payback for all the primary systems.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 11: To analyze how upgrading IT equipment impacts energy cost savings and identify specific examples demonstrating these advantages, consider the following:\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 12: How do variable-speed chillers enhance efficiency by adapting to changing cooling load conditions in data centers?\n",
      "A: Let's think step by step in order to Variable-speed chillers enhance efficiency by adapting to changing cooling load conditions in data centers by adjusting their speed to match the cooling demand. This allows them to operate at higher efficiency levels compared to traditional chillers that run at a fixed speed. By optimizing their speed, variable-speed chillers can reduce energy consumption and improve overall cooling system efficiency.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 13: How can tracking server applications and adjusting temperature settings enhance energy efficiency in data centers?\n",
      "A: Tracking server applications and adjusting temperature settings can enhance energy efficiency in data centers in several ways:\n",
      "\n",
      "1. **Server Application Tracking**: Regularly monitoring and updating a server inventory can help identify applications running on servers and detect any unused or underutilized servers. Shutting down or consolidating these servers can significantly reduce energy consumption.\n",
      "\n",
      "2. **Temperature Adjustment**: Raising the air temperature at the IT equipment inlet to the high end of ASHRAE's recommended limit (up to 80¬∞F or higher) can significantly reduce cooling energy usage. This adjustment is possible because modern IT equipment can operate at higher temperatures without compromising reliability.\n",
      "\n",
      "By implementing these strategies, data centers can achieve better energy efficiency, lower energy costs, and contribute to a more sustainable environment.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 14: Examine the role of bespoke cooling solutions in optimizing energy efficiency for server environments.\n",
      "\n",
      "A: Let's think step by step in order to To address this question, we need to examine the resources and identify the role of bespoke cooling solutions in optimizing energy efficiency for server environments.\n",
      "\n",
      "1. **Custom Airflow Management**: Implementing custom airflow management strategies, such as hot and cold aisle containment, can help ensure that cool air is directed to where it is needed and that hot air is properly exhausted. This can reduce the amount of energy required for cooling and improve overall efficiency.\n",
      "\n",
      "2. **In-Row Cooling**: In-row cooling solutions, such as Rear Door Heat Exchangers (RDHX), can capture exhaust heat directly from server racks, improving cooling efficiency. These solutions can be customized to fit the specific needs of a data center or server room.\n",
      "\n",
      "3. **Variable Speed Fans**: Variable speed fans can be used in cooling systems to adjust airflow based on real-time cooling needs. This can reduce excess airflow and energy consumption.\n",
      "\n",
      "4. **Air-Side Economizers**: Air-side economizers can be used to utilize outside air for cooling when conditions permit. This can involve exhaust fans and intake openings or fans with economizer capabilities.\n",
      "\n",
      "By incorporating these bespoke cooling solutions, server environments can significantly improve cooling efficiency and reduce energy costs.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 15: Examine the role of bespoke cooling solutions in optimizing energy efficiency for server environments.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 16: Imagine you are a data center manager tasked with reducing energy consumption in your server room. You have access to a language model that can provide information and recommendations on energy-saving measures. Your task is to use the language model to research and propose energy-saving measures for your server room.\n",
      "\n",
      "You are given the following context:\n",
      "\n",
      "Context: ['[0]SmallServerRooms_Final Report Task 2.13_2013https://datacenters.lbl.gov/resources/energy-efficiency-small-server-rooms-0\\n\\n# LEGAL NOTICE\\n\\nThe Lawrence Berkeley National Laboratory, a laboratory owned by DOE, is located at 1 Cyclotron Rd., Berkeley, California is a national laboratory of the DOE managed by Regents of the University of California for the U.S. Department of Energy under Contract Number DE- AC02-05CH11231. This report was prepared as an account of work sponsored by the Sponsor and pursuant to an M&O Contract with the United States Department of Energy (DOE). Neither Regents of the University of California, nor the DOE, nor the Sponsor, nor any of their employees, contractors, or subcontractors, makes any warranty, express or implied, or assumes any legal liability or responsibility for the accuracy, completeness, or usefulness of any information, apparatus, product, or process disclosed, or represents that its use would not infringe on privately owned rights. Reference herein to any specific commercial product, process, or service by trade name, trademark, manufacturer, or otherwise, does not necessarily constitute or imply its endorsement, recommendation, or favoring by Regents of the University of California, or the DOE, or the Sponsor. The views and opinions of authors expressed herein do not necessarily state or reflect those of Regents of the University of California, the DOE, or the Sponsor, or any of their employees, or the Government, or any agency thereof, or the State of California. This report has not been approved or disapproved by Regents of the University of California, the DOE, or the Sponsor, nor has Regents of the University of California, the DOE, or the Sponsor passed upon the accuracy or adequacy of the information in this report.\\n\\ni\\n\\n\\n# DISCLAIMER', '[1]USER GUIDE FOR IMPLEMENTING ECBC_v9.2_06_May 2021_0https://datacenters.lbl.gov/resources/ecbc-2017-data-center-user-guide\\n\\nLevel I: ECBC Compliant and any recommended additional requirements.\\nLevel II: ECBC+ and any recommended additional requirements.\\nLevel III: SuperECBC and any recommended additional requirements.\\n\\nNote that Level Il and Level III requirements build on lower-level requirements and only higher efficiency levels or additional requirements are specified. That is, all Level II criteria inherently include, and are incrementally more efficient than, Level I requirements; Level III requirements are incrementally more efficient than those in Level II. The table below provides an example of the format for each of the sections that follow.\\n\\n5\\n\\n\\n## Table Illustrating Compliance Levels\\n\\n\\n\\nLevel I\\tLevel II\\tLevel III\\nECBC Compliant\\tECBC+\\tSuperECBC\\nReference to ECBC 2017 Section\\tReference to ECBC 2017 Section\\tReference to ECBC 2017 Section\\nNumber if applicable.\\tNumber if applicable.\\tNumber if applicable.\\nListed requirements to achieve\\tListed requirements to\\tListed requirements to\\nECBC Compliant level.\\tachieve ECBC+ level.\\tachieve SuperECBC level.\\nRecommended Additional\\nRecommended Additional\\tRecommended Additional\\nRequirements\\nAdditional requirements (if any) to\\tAdditional requirements (if any) to\\tAdditional requirements (if any) to\\tachieve this level that are not\\nachieve this level that are not\\tachieve this level that are not\\ndirectly addressed by ECBC 2017.\\tdirectly addressed by ECBC 2017\\tdirectly addressed by ECBC 2017\\tor at Level / or II.\\nor at Level I.\\n\\n\\n\\nEach table is followed by Tips and Best Practices for meeting or exceeding the requirements and achieving operational efficiencies. Each section also includes Resources or Citations to various sources of information on the measures, their energy performance or implementation.\\n\\n## Performance Approach', '\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 17: Given the fields `context`, `question`, produce the fields `response`.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: 18: You are a data center energy efficiency expert, and you have been tasked with providing information about energy-saving strategies in data centers. A client has asked you about the benefits of using variable-speed chillers in data centers. They want to know how these chillers enhance efficiency by adapting to changing cooling load conditions.\n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2024/11/20 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the default program...\n",
      "\n",
      "Average Metric: 2.0553467000835424 / 15  (13.7): 100%|██████████| 15/15 [00:38<00:00,  2.55s/it]\n",
      "2024/11/20 20:08:07 INFO dspy.evaluate.evaluate: Average Metric: 2.0553467000835424 / 15 (13.7%)\n",
      "2024/11/20 20:08:07 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 13.7\n",
      "\n",
      "2024/11/20 20:08:07 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2024/11/20 20:08:07 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "/Users/eliastavarez/Berkeley/w210/greencompute-backend/.venv/lib/python3.11/site-packages/optuna/_experimental.py:30: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2024/11/20 20:08:07 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 1 / 25 =====\n",
      "Average Metric: 8.82455701781128 / 15  (58.8): 100%|██████████| 15/15 [00:26<00:00,  1.74s/it]  \n",
      "2024/11/20 20:08:33 INFO dspy.evaluate.evaluate: Average Metric: 8.82455701781128 / 15 (58.8%)\n",
      "2024/11/20 20:08:33 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 58.83\n",
      "2024/11/20 20:08:33 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 58.83 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 7'].\n",
      "2024/11/20 20:08:33 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83]\n",
      "2024/11/20 20:08:33 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 58.83\n",
      "2024/11/20 20:08:33 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/20 20:08:33 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 25 =====\n",
      "Average Metric: 8.861393070866754 / 15  (59.1): 100%|██████████| 15/15 [00:27<00:00,  1.80s/it] \n",
      "2024/11/20 20:09:00 INFO dspy.evaluate.evaluate: Average Metric: 8.861393070866754 / 15 (59.1%)\n",
      "2024/11/20 20:09:00 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 59.08\n",
      "2024/11/20 20:09:00 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 59.08 with parameters ['Predictor 0: Instruction 10', 'Predictor 0: Few-Shot Set 7'].\n",
      "2024/11/20 20:09:00 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08]\n",
      "2024/11/20 20:09:00 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 59.08\n",
      "2024/11/20 20:09:00 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/20 20:09:00 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 25 =====\n",
      "Average Metric: 9.304211918685603 / 15  (62.0): 100%|██████████| 15/15 [00:36<00:00,  2.45s/it]\n",
      "2024/11/20 20:09:37 INFO dspy.evaluate.evaluate: Average Metric: 9.304211918685603 / 15 (62.0%)\n",
      "2024/11/20 20:09:37 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 62.03\n",
      "2024/11/20 20:09:37 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 62.03 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 18'].\n",
      "2024/11/20 20:09:37 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03]\n",
      "2024/11/20 20:09:37 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:09:37 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/20 20:09:37 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 25 =====\n",
      "Average Metric: 0.5714285714285715 / 1  (57.1):   7%|▋         | 1/15 [00:16<03:46, 16.18s/it]2024/11/20 20:09:53 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 7.092184419649209 / 12  (59.1):  80%|████████  | 12/15 [00:32<00:04,  1.58s/it]2024/11/20 20:10:10 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 8.292184419649208 / 15  (55.3): 100%|██████████| 15/15 [00:41<00:00,  2.77s/it]\n",
      "2024/11/20 20:10:18 INFO dspy.evaluate.evaluate: Average Metric: 8.292184419649208 / 15 (55.3%)\n",
      "2024/11/20 20:10:18 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 55.28 with parameters ['Predictor 0: Instruction 15', 'Predictor 0: Few-Shot Set 2'].\n",
      "2024/11/20 20:10:18 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28]\n",
      "2024/11/20 20:10:18 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:10:18 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/20 20:10:18 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 25 =====\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:10:32 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 0.0 / 1  (0.0):   7%|▋         | 1/15 [00:14<03:18, 14.20s/it]2024/11/20 20:10:33 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 0.0 / 2  (0.0):   7%|▋         | 1/15 [00:15<03:18, 14.20s/it]2024/11/20 20:10:33 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 0.0 / 3  (0.0):  13%|█▎        | 2/15 [00:15<01:23,  6.39s/it]2024/11/20 20:10:34 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 0.5714285714285715 / 5  (11.4):  33%|███▎      | 5/15 [00:16<00:20,  2.05s/it]2024/11/20 20:10:35 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 1.4214285714285715 / 7  (20.3):  47%|████▋     | 7/15 [00:18<00:11,  1.41s/it]2024/11/20 20:10:37 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 2.854761904761905 / 10  (28.5):  67%|██████▋   | 10/15 [00:22<00:07,  1.52s/it]2024/11/20 20:10:41 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 2.854761904761905 / 11  (26.0):  73%|███████▎  | 11/15 [00:22<00:04,  1.18s/it]2024/11/20 20:10:49 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 8', 'Predictor 0: Few-Shot Set 18'].\n",
      "2024/11/20 20:10:49 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0]\n",
      "2024/11/20 20:10:49 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:10:49 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/20 20:10:49 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:11:16 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 1'].\n",
      "2024/11/20 20:11:16 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0]\n",
      "2024/11/20 20:11:16 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:11:16 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/20 20:11:16 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:11:57 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 12'].\n",
      "2024/11/20 20:11:57 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:11:57 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:11:57 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/20 20:11:57 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 25 =====\n",
      "Average Metric: 2.854761904761905 / 11  (26.0):  73%|███████▎  | 11/15 [01:38<00:35,  8.99s/it]\n",
      "  0%|          | 0/15 [01:08<?, ?it/s]\n",
      "  0%|          | 0/15 [00:41<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:12:37 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 11', 'Predictor 0: Few-Shot Set 13'].\n",
      "2024/11/20 20:12:37 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:12:37 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:12:37 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/20 20:12:37 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:13:14 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 4'].\n",
      "2024/11/20 20:13:14 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:13:14 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:13:14 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/20 20:13:14 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:13:45 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 14', 'Predictor 0: Few-Shot Set 1'].\n",
      "2024/11/20 20:13:45 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:13:45 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:13:45 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:13:45 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:14:19 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 18'].\n",
      "2024/11/20 20:14:19 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:14:19 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:14:19 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:14:19 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 12 / 25 =====\n",
      "  0%|          | 0/15 [01:41<?, ?it/s]\n",
      "  0%|          | 0/15 [01:04<?, ?it/s]\n",
      "  0%|          | 0/15 [00:33<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:15:02 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 10', 'Predictor 0: Few-Shot Set 2'].\n",
      "2024/11/20 20:15:02 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:15:02 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:15:02 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:15:02 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:15:31 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 7'].\n",
      "2024/11/20 20:15:31 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:15:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:15:31 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:15:31 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 14 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:16:03 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 10', 'Predictor 0: Few-Shot Set 15'].\n",
      "2024/11/20 20:16:03 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:16:03 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:16:03 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:16:03 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 15 / 25 =====\n",
      "  0%|          | 0/15 [01:00<?, ?it/s]\n",
      "  0%|          | 0/15 [00:32<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:16:43 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 8'].\n",
      "2024/11/20 20:16:43 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:16:43 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:16:43 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:16:43 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 16 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:17:10 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 10', 'Predictor 0: Few-Shot Set 7'].\n",
      "2024/11/20 20:17:10 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:17:10 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:17:10 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:17:10 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 17 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:17:39 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 13', 'Predictor 0: Few-Shot Set 10'].\n",
      "2024/11/20 20:17:39 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:17:39 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:17:39 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:17:39 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 18 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:56<?, ?it/s]\n",
      "  0%|          | 0/15 [00:29<?, ?it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:18:19 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 6'].\n",
      "2024/11/20 20:18:19 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:18:19 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:18:19 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:18:19 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 19 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:18:58 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 18', 'Predictor 0: Few-Shot Set 3'].\n",
      "2024/11/20 20:18:58 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:18:58 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:18:58 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:18:58 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 20 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:19:29 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 14', 'Predictor 0: Few-Shot Set 16'].\n",
      "2024/11/20 20:19:29 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:19:29 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:19:29 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:19:29 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 21 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [01:10<?, ?it/s]\n",
      "  0%|          | 0/15 [00:30<?, ?it/s]\n",
      "Average Metric: 0.5 / 1  (50.0):   7%|▋         | 1/15 [00:10<02:27, 10.51s/it]2024/11/20 20:19:58 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 5'].\n",
      "2024/11/20 20:19:58 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:19:58 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:19:58 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:19:58 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 22 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:20:28 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 10'].\n",
      "2024/11/20 20:20:28 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:20:28 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:20:28 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:20:28 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 23 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:21:00 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 7'].\n",
      "2024/11/20 20:21:00 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:21:00 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:21:00 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:21:00 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 24 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [01:02<?, ?it/s]\n",
      "  0%|          | 0/15 [00:32<?, ?it/s]\n",
      "Average Metric: 0.8333333333333334 / 1  (83.3):   7%|▋         | 1/15 [00:14<03:21, 14.39s/it]2024/11/20 20:21:30 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 9', 'Predictor 0: Few-Shot Set 7'].\n",
      "2024/11/20 20:21:30 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:21:30 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:21:30 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:21:30 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 25 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [09:32<?, ?it/s]\n",
      "  0%|          | 0/15 [07:11<?, ?it/s]\n",
      "  0%|          | 0/15 [05:27<?, ?it/s]\n",
      "  0%|          | 0/15 [03:50<?, ?it/s]\n",
      "Average Metric: 0.5 / 1  (50.0):   7%|▋         | 1/15 [02:01<28:18, 121.29s/it]\n",
      "Average Metric: 0.8333333333333334 / 1  (83.3):   7%|▋         | 1/15 [00:29<06:54, 29.60s/it]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/20 20:22:04 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 17', 'Predictor 0: Few-Shot Set 17'].\n",
      "2024/11/20 20:22:04 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [13.7, 58.83, 59.08, 62.03, 55.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/20 20:22:04 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 62.03\n",
      "2024/11/20 20:22:04 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/20 20:22:04 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 62.03!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens per min, please wait before trying again.\n"
     ]
    }
   ],
   "source": [
    "metric = SemanticF1()\n",
    "tp = dspy.MIPROv2(metric=metric, auto=\"medium\", num_threads=24)  # use fewer threads if your rate limit is small\n",
    "\n",
    "optimized_rag = tp.compile(\n",
    "    RAG(), \n",
    "    trainset=trainset, \n",
    "    valset=valset,\n",
    "\tmax_bootstrapped_demos=2,\n",
    " \tmax_labeled_demos=2,\n",
    "  \trequires_permission_to_run=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_rag.save(\"output/optimized_rag_v2.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
