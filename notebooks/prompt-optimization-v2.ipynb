{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dspy\n",
    "from dspy.evaluate import SemanticF1\n",
    "import json\n",
    "import requests\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to setup datset and evaluation\n",
    "def create_dataset(path: str) -> list[dspy.Example]:\n",
    "\tdataset = pd.read_excel(path)\n",
    "\tdataset_dict = dataset.to_dict(orient='records')\n",
    "\tdspy_dataset = []\n",
    "\n",
    "\tfor row in dataset_dict:\n",
    "\t\tdspy_dataset.append(dspy.Example(question=row['input'], response=row['expected_output']).with_inputs(\"question\"))\n",
    "\n",
    "\tprint(f\"Dataset length: {len(dspy_dataset)}\")\n",
    "\treturn dspy_dataset\n",
    "\n",
    "def create_sets(dataset: list[dspy.Example], metric: dspy.Module = SemanticF1()):\n",
    "\ttrainset, valset, devset, testset = dataset[:15], dataset[15:30], dataset[30:40], dataset[40:]\n",
    "\tevaluate = dspy.Evaluate(devset=devset, metric=metric, num_threads=24, display_progress=True, display_table=3)\n",
    "\n",
    "\tfor name, set in zip([trainset, valset, devset, testset], [\"trainset\", \"valset\", \"devset\", \"testset\"]):\n",
    "\t\tprint(f\"{set} length: {len(name)}\")\n",
    "\n",
    "\treturn trainset, valset, devset, testset, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 52\n",
      "trainset length: 15\n",
      "valset length: 15\n",
      "devset length: 10\n",
      "testset length: 12\n"
     ]
    }
   ],
   "source": [
    "dspy_dataset = create_dataset(\"synthetics/synthetic_dataset_revised.xlsx\")\n",
    "trainset, valset, devset, testset, evaluate = create_sets(dspy_dataset)\n",
    "\n",
    "# Save the testset to a file\n",
    "with open(\"testset.json\", \"w\") as f:\n",
    "\tjson.dump([example.toDict() for example in testset], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, top_k: int) -> list[str]:\n",
    "    url = \"http://greencompute-1575332443.us-east-1.elb.amazonaws.com/api/llm/retrieval\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"query\": query,\n",
    "        \"top_k\": top_k\n",
    "    }\n",
    "\n",
    "    documents = requests.post(url, headers=headers, json=data).json()[\"documents\"]\n",
    "    return [f\"[{i}]\" + doc[\"doc_title\"] + doc[\"url\"] + \"\\n\\n\" + doc[\"content\"] for i, doc in enumerate(documents)]\n",
    "\n",
    "class TitanLM(dspy.LM):\n",
    "    def __init__(self, model: str, client, max_tokens: int = 1024, temperature: float = 0.7, top_p: float = 0.9, **kwargs):\n",
    "        self.client = client\n",
    "        self.history = []\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = 1024\n",
    "        self.top_p = top_p\n",
    "\n",
    "        super().__init__(model, **kwargs)\n",
    "        self.model = model\n",
    "    \n",
    "    def _format_message(self, prompt: str):\n",
    "        body = json.dumps(\n",
    "            {\n",
    "                \"inputText\": prompt,\n",
    "                \"textGenerationConfig\": {\n",
    "                    \"maxTokenCount\": self.max_tokens,\n",
    "                    \"stopSequences\": [],\n",
    "                    \"temperature\": self.temperature,\n",
    "                    \"topP\": self.top_p,\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "        return body\n",
    "\n",
    "    def generate_content(self, prompt: str) -> str:\n",
    "        body = self._format_message(prompt)\n",
    "        response = self.client.invoke_model(\n",
    "            body=body,\n",
    "            modelId=self.model,\n",
    "            accept=\"application/json\",\n",
    "            contentType=\"application/json\",\n",
    "        )\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "        return response_body.get(\"results\")\n",
    "\n",
    "    def __call__(self, prompt=None, messages=None, **kwargs):\n",
    "        # Custom chat model working for text completion model\n",
    "        prompt = '\\n\\n'.join([x['content'] for x in messages] + ['BEGIN RESPONSE:'])\n",
    "\n",
    "        completions = self.generate_content(prompt)\n",
    "        self.history.append({\"prompt\": prompt, \"completions\": completions})\n",
    "\n",
    "        # Must return a list of strings\n",
    "        return [completions[0].get(\"outputText\")]\n",
    "\n",
    "    def inspect_history(self):\n",
    "        for interaction in self.history:\n",
    "            print(f\"Prompt: {interaction['prompt']} -> Completions: {interaction['completions']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_docs=20):\n",
    "        self.num_docs = num_docs\n",
    "        self.respond = dspy.ChainOfThought('context, question -> response')\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = search(question, top_k=self.num_docs)\n",
    "        return self.respond(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = TitanLM(\"amazon.titan-text-premier-v1:0\", client=boto3.client(\"bedrock-runtime\"))\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The document discusses data center energy efficiency.',\n",
       "    response='1. Perform an energy assessment.\\n2. Understand the data center cooling system.\\n3. Implement an energy management plan.\\n4. Monitor and measure energy use.\\n5. Upgrade to energy efficient equipment.'\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag = RAG()\n",
    "rag(question=\"How do I increase my data center efficiency?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.1749871991807477 / 10  (21.7): 100%|██████████| 10/10 [00:24<00:00,  2.49s/it]\n",
      "2024/11/12 19:07:13 INFO dspy.evaluate.evaluate: Average Metric: 2.1749871991807477 / 10 (21.7%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_27d03 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_27d03 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_27d03_row0_col0, #T_27d03_row0_col1, #T_27d03_row0_col2, #T_27d03_row0_col3, #T_27d03_row0_col4, #T_27d03_row1_col0, #T_27d03_row1_col1, #T_27d03_row1_col2, #T_27d03_row1_col3, #T_27d03_row1_col4, #T_27d03_row2_col0, #T_27d03_row2_col1, #T_27d03_row2_col2, #T_27d03_row2_col3, #T_27d03_row2_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_27d03\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_27d03_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_27d03_level0_col1\" class=\"col_heading level0 col1\" >example_response</th>\n",
       "      <th id=\"T_27d03_level0_col2\" class=\"col_heading level0 col2\" >reasoning</th>\n",
       "      <th id=\"T_27d03_level0_col3\" class=\"col_heading level0 col3\" >pred_response</th>\n",
       "      <th id=\"T_27d03_level0_col4\" class=\"col_heading level0 col4\" >SemanticF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_27d03_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_27d03_row0_col0\" class=\"data row0 col0\" >What factors, including multi-tenancy and operator incentives, contribute to cloud's lower environmental impact?</td>\n",
       "      <td id=\"T_27d03_row0_col1\" class=\"data row0 col1\" >Cloud services generally have a lower environmental impact due to several key factors: 1. **Multi-tenancy**: This concept allows multiple customers to share resources, leading to...</td>\n",
       "      <td id=\"T_27d03_row0_col2\" class=\"data row0 col2\" >The context does not mention anything about cloud's lower environmental impact.</td>\n",
       "      <td id=\"T_27d03_row0_col3\" class=\"data row0 col3\" >I cannot answer this question based on the given context.</td>\n",
       "      <td id=\"T_27d03_row0_col4\" class=\"data row0 col4\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27d03_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_27d03_row1_col0\" class=\"data row1 col0\" >Identify how virtualization, power management, and cloud computing reduce energy waste and enhance business operations in server rooms.</td>\n",
       "      <td id=\"T_27d03_row1_col1\" class=\"data row1 col1\" >Virtualization reduces energy waste in server rooms by allowing multiple virtual machines to run on a single physical server, optimizing hardware usage and decreasing the...</td>\n",
       "      <td id=\"T_27d03_row1_col2\" class=\"data row1 col2\" >I cannot find sufficient information to answer the question.</td>\n",
       "      <td id=\"T_27d03_row1_col3\" class=\"data row1 col3\" >Sorry, I cannot find sufficient information to answer the question.</td>\n",
       "      <td id=\"T_27d03_row1_col4\" class=\"data row1 col4\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27d03_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_27d03_row2_col0\" class=\"data row2 col0\" >How do virtualization and cloud computing synergistically enhance server room energy efficiency and utilization rates?</td>\n",
       "      <td id=\"T_27d03_row2_col1\" class=\"data row2 col1\" >Virtualization and cloud computing work together to significantly enhance server room energy efficiency and utilization rates by improving resource allocation and reducing energy consumption. Virtualization...</td>\n",
       "      <td id=\"T_27d03_row2_col2\" class=\"data row2 col2\" >I cannot find sufficient information to answer the question.</td>\n",
       "      <td id=\"T_27d03_row2_col3\" class=\"data row2 col3\" >Sorry, I cannot find sufficient information to answer the question.</td>\n",
       "      <td id=\"T_27d03_row2_col4\" class=\"data row2 col4\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16d7feb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 7 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "21.75"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(RAG())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/12 19:45:09 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING MEDIUM AUTO RUN SETTINGS:\n",
      "num_trials: 25\n",
      "minibatch: False\n",
      "num_candidates: 19\n",
      "valset size: 15\n",
      "\n",
      "2024/11/12 19:45:09 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2024/11/12 19:45:09 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2024/11/12 19:45:09 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=19 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/19\n",
      "Bootstrapping set 2/19\n",
      "Bootstrapping set 3/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [02:29<00:23, 11.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 13 examples for up to 1 rounds, amounting to 13 attempts.\n",
      "Bootstrapping set 4/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [01:09<01:01,  8.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 8 examples for up to 1 rounds, amounting to 8 attempts.\n",
      "Bootstrapping set 5/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:16<03:56, 16.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 6/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:41<02:47, 13.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 7/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [01:47<03:35, 21.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 8/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:08<01:54,  8.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 9/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:34<02:18, 11.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 10/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [01:35<02:22, 15.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "Bootstrapping set 11/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [00:37<01:43,  9.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 12/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:49<03:19, 16.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 13/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [01:29<01:42, 12.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 7 examples for up to 1 rounds, amounting to 7 attempts.\n",
      "Bootstrapping set 14/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [01:38<01:05, 10.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 9 examples for up to 1 rounds, amounting to 9 attempts.\n",
      "Bootstrapping set 15/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:15<03:36, 15.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 16/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [01:21<02:02, 13.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "Bootstrapping set 17/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:11<02:40, 11.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 18/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:28<03:04, 14.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 19/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:36<03:54, 18.01s/it]\n",
      "2024/11/12 20:01:21 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2024/11/12 20:01:21 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/12 20:01:33 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing instructions...\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Given the fields `context`, `question`, produce the fields `response`.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Given the fields `context`, `question`, generate the fields `reasoning`, `response`.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 2: As a Data Center Engineer, you are responsible for optimizing the energy efficiency of the data center. You have been asked to explore advanced airflow management techniques for enhancing efficiency in server room cooling systems. \n",
      "\n",
      "To complete this task, search the given context for information on advanced airflow management techniques.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Please provide a comparison between high-efficiency cooling units and traditional cooling systems in terms of energy savings for server rooms. Additionally, discuss the cost-effectiveness of installing high-efficiency cooling units.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 4: Examine advanced cooling strategies to maximize energy efficiency in high-density data center environments.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 5: Imagine you are a data center energy consultant tasked with optimizing the energy efficiency of a small server room. You have access to a vast repository of resources and documents related to data center energy assessments. Your client is counting on you to provide expert recommendations to reduce energy costs while maintaining optimal performance. Using the information provided in the context and your knowledge of data center energy assessments, generate a comprehensive response outlining energy-saving measures that can optimize efficiency in small server rooms with varied configurations.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 6: How can I improve the energy efficiency of my data center's cooling system?\n",
      "\n",
      "A: To improve the energy efficiency of your data center's cooling system, consider implementing advanced cooling strategies such as hot and cold aisle containment, variable speed fans, free cooling, liquid cooling, and in-row cooling. These strategies can help you maximize energy efficiency and reduce energy costs in high-density data center environments. Additionally, consider conducting an energy assessment to identify specific energy-saving opportunities and best practices for your data center.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 7: To analyze the energy efficiency of rack-level cooling systems versus traditional cooling methods in server environments, consider the following:\n",
      "1. Understand the concept of rack-level cooling systems and their design principles.\n",
      "2. Study the energy consumption patterns of traditional cooling methods in server environments.\n",
      "3. Compare the energy efficiency of rack-level cooling systems with traditional cooling methods, taking into account factors such as cooling capacity, energy usage, and overall system efficiency.\n",
      "4. Evaluate the potential energy savings and cost reductions that can be achieved by implementing rack-level cooling systems in server environments.\n",
      "5. Consider any additional benefits or challenges associated with rack-level cooling systems, such as maintenance requirements, installation considerations, and compatibility with existing infrastructure.\n",
      "6. Draw conclusions based on the analysis and provide recommendations for optimizing energy efficiency in server environments through the use of rack-level cooling systems or other appropriate cooling solutions.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 8: How does upgrading IT equipment impact energy cost savings?\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 9: What energy-saving measures can optimize efficiency in small server rooms with varied configurations?\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 10: Imagine you are a data center manager tasked with reducing energy costs. You have access to a set of documents that provide information about energy efficiency in server rooms and data centers. Your task is to analyze how upgrading IT equipment impacts energy cost savings and identify specific examples demonstrating these advantages.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 11: What are the benefits of customized cooling solutions in server environments?\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 12: To enhance energy efficiency and reduce consumption, data center operators can consider the following strategies:\n",
      "\n",
      "1. Optimizing server utilization: By ensuring that servers are running at optimal capacity, operators can reduce energy waste and improve overall efficiency.\n",
      "\n",
      "2. Implementing virtualization and consolidation: Virtualization allows multiple virtual machines to run on a single physical server, reducing the number of physical servers needed and cutting energy consumption.\n",
      "\n",
      "3. Using energy-efficient hardware and equipment: Upgrading to energy-efficient servers, storage devices, and networking equipment can significantly reduce energy consumption.\n",
      "\n",
      "4. Implementing energy management systems: Energy management systems can help operators monitor and control energy usage, identify areas for improvement, and implement energy-saving measures.\n",
      "\n",
      "5. Utilizing renewable energy sources: Data centers can reduce their reliance on fossil fuels by using renewable energy sources such as solar, wind, and hydro power.\n",
      "\n",
      "6. Cooling system optimization: Optimizing cooling systems can help reduce energy consumption and improve overall efficiency. This can include implementing energy-efficient cooling technologies, optimizing airflow, and using cold aisle containment.\n",
      "\n",
      "7. Power distribution optimization: Optimizing power distribution can help reduce energy consumption and improve overall efficiency. This can include implementing energy-efficient power distribution equipment, using power strips to manage power usage, and optimizing power usage effectiveness (PUE).\n",
      "\n",
      "8. Rack layout optimization: Optimizing the layout of server racks can help improve airflow and reduce energy consumption. This can include using hot aisle/cold aisle containment, optimizing the placement of equipment, and using energy-efficient rack designs.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 13: How can tracking server applications and adjusting temperature settings enhance energy efficiency in data centers?\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 14: What multi-faceted strategies can data center operators employ to enhance energy efficiency and reduce consumption?\n",
      "A: To address this question, we need to explore the various energy-saving measures that can be implemented in data centers. These strategies can encompass different aspects of data center design, operation, and equipment. By examining relevant resources and studies, we can identify the key approaches that data center operators can adopt to enhance energy efficiency and reduce energy consumption.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 15: Examine the role of bespoke cooling solutions in optimizing energy efficiency for server environments.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 16: You are a researcher tasked with comparing the energy efficiency of different cooling methods for server environments. A major tech company is relying on your analysis to make an informed decision about which cooling method to use in their data centers. You have been provided with a dataset containing information about various cooling technologies, including rack-level cooling systems and traditional cooling methods. Your task is to use this dataset to analyze the energy efficiency of rack-level cooling systems versus traditional cooling methods in server environments.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 17: To get the response, given the context and the question, follow these steps:\n",
      "1. Read the context carefully to understand the information provided.\n",
      "2. Identify the key points in the question that need to be addressed.\n",
      "3. Use the context to find the relevant information that answers the question.\n",
      "4. Provide a clear and concise response that addresses the question based on the information in the context.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: 18: In a scenario where you are a data center manager tasked with reducing energy consumption, and thus costs, while maintaining or improving performance, and you have access to a context that provides information about the data center and its operations, and a question asking what specific data is required for each Primary System to estimate energy savings, including impact, cost, payback, and completion timeframe, you would need to generate a response that provides a list of the specific data required for each Primary System to estimate energy savings.\n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2024/11/12 20:04:52 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the default program...\n",
      "\n",
      "Average Metric: 3.2728070175440993 / 15  (21.8): 100%|██████████| 15/15 [00:23<00:00,  1.56s/it]\n",
      "2024/11/12 20:05:16 INFO dspy.evaluate.evaluate: Average Metric: 3.2728070175440993 / 15 (21.8%)\n",
      "2024/11/12 20:05:16 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 21.82\n",
      "\n",
      "2024/11/12 20:05:16 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2024/11/12 20:05:16 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2024/11/12 20:05:16 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 1 / 25 =====\n",
      "Average Metric: 8.637917393675593 / 15  (57.6): 100%|██████████| 15/15 [00:30<00:00,  2.05s/it] \n",
      "2024/11/12 20:05:46 INFO dspy.evaluate.evaluate: Average Metric: 8.637917393675593 / 15 (57.6%)\n",
      "2024/11/12 20:05:46 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 57.59\n",
      "2024/11/12 20:05:46 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 57.59 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 7'].\n",
      "2024/11/12 20:05:46 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59]\n",
      "2024/11/12 20:05:46 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 57.59\n",
      "2024/11/12 20:05:46 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/12 20:05:46 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 25 =====\n",
      "Average Metric: 10.396715931258528 / 15  (69.3): 100%|██████████| 15/15 [00:34<00:00,  2.29s/it]\n",
      "2024/11/12 20:06:21 INFO dspy.evaluate.evaluate: Average Metric: 10.396715931258528 / 15 (69.3%)\n",
      "2024/11/12 20:06:21 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 69.31\n",
      "2024/11/12 20:06:21 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 69.31 with parameters ['Predictor 0: Instruction 10', 'Predictor 0: Few-Shot Set 7'].\n",
      "2024/11/12 20:06:21 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31]\n",
      "2024/11/12 20:06:21 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:06:21 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/12 20:06:21 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 25 =====\n",
      "Average Metric: 2.2358241758241757 / 4  (55.9):  20%|██        | 3/15 [00:21<01:03,  5.29s/it]2024/11/12 20:06:43 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 3.721538461538462 / 7  (53.2):  47%|████▋     | 7/15 [00:23<00:12,  1.56s/it] 2024/11/12 20:06:45 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 5.324135864135864 / 11  (48.4):  73%|███████▎  | 11/15 [00:26<00:04,  1.01s/it] 2024/11/12 20:06:51 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 7.002707292707293 / 15  (46.7): 100%|██████████| 15/15 [00:34<00:00,  2.29s/it]\n",
      "2024/11/12 20:06:55 INFO dspy.evaluate.evaluate: Average Metric: 7.002707292707293 / 15 (46.7%)\n",
      "2024/11/12 20:06:55 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 46.68 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 18'].\n",
      "2024/11/12 20:06:55 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68]\n",
      "2024/11/12 20:06:55 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:06:55 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/12 20:06:55 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 25 =====\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:07:01 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 0.0 / 1  (0.0):   7%|▋         | 1/15 [00:05<01:22,  5.88s/it]2024/11/12 20:07:06 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 0.0 / 2  (0.0):  13%|█▎        | 2/15 [00:10<01:09,  5.36s/it]2024/11/12 20:07:06 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 0.0 / 3  (0.0):  20%|██        | 3/15 [00:11<00:36,  3.07s/it]2024/11/12 20:07:07 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 0.0 / 4  (0.0):  27%|██▋       | 4/15 [00:11<00:21,  1.97s/it]2024/11/12 20:07:10 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 0.0 / 5  (0.0):  33%|███▎      | 5/15 [00:14<00:22,  2.26s/it]2024/11/12 20:07:11 ERROR dspy.evaluate.evaluate: Error for example in dev set: \t\t An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 0.0 / 6  (0.0):  40%|████      | 6/15 [00:15<00:16,  1.84s/it]2024/11/12 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 15', 'Predictor 0: Few-Shot Set 2'].\n",
      "2024/11/12 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0]\n",
      "2024/11/12 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/12 20:07:28 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:08:02 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 8', 'Predictor 0: Few-Shot Set 18'].\n",
      "2024/11/12 20:08:02 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0]\n",
      "2024/11/12 20:08:02 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:08:02 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/12 20:08:02 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:08:35 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 1'].\n",
      "2024/11/12 20:08:35 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:08:35 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:08:35 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/12 20:08:35 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 25 =====\n",
      "  0%|          | 0/15 [01:06<?, ?it/s]\n",
      "  0%|          | 0/15 [00:32<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.425003357507387 / 9  (49.2):  60%|██████    | 9/15 [00:25<00:10,  1.72s/it] 2024/11/12 20:09:16 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 12'].\n",
      "2024/11/12 20:09:16 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:09:16 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:09:16 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/12 20:09:16 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:09:50 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 11', 'Predictor 0: Few-Shot Set 13'].\n",
      "2024/11/12 20:09:50 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:09:50 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:09:50 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/12 20:09:50 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.1188903330838813 / 5  (62.4):  33%|███▎      | 5/15 [00:22<00:28,  2.81s/it]2024/11/12 20:10:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 4'].\n",
      "2024/11/12 20:10:23 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:10:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:10:23 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2024/11/12 20:10:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:10:59 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 14', 'Predictor 0: Few-Shot Set 1'].\n",
      "2024/11/12 20:10:59 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:10:59 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:10:59 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:10:59 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 25 =====\n",
      "  0%|          | 0/15 [01:43<?, ?it/s]\n",
      "Average Metric: 3.1188903330838813 / 5  (62.4):  33%|███▎      | 5/15 [01:09<02:19, 13.92s/it]\n",
      "  0%|          | 0/15 [00:35<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.10145182069291 / 14  (50.7):  93%|█████████▎| 14/15 [00:28<00:01,  1.77s/it]  2024/11/12 20:11:28 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 17', 'Predictor 0: Few-Shot Set 17'].\n",
      "2024/11/12 20:11:28 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:11:28 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:11:28 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:11:28 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 12 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:12:06 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 7'].\n",
      "2024/11/12 20:12:06 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:12:06 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:12:06 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:12:06 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:12:42 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 7'].\n",
      "2024/11/12 20:12:42 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:12:42 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:12:42 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:12:42 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 14 / 25 =====\n",
      "  0%|          | 0/15 [01:13<?, ?it/s]\n",
      "  0%|          | 0/15 [00:36<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.9466230936819913 / 7  (27.8):  47%|████▋     | 7/15 [00:16<00:11,  1.48s/it]2024/11/12 20:13:11 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 10', 'Predictor 0: Few-Shot Set 0'].\n",
      "2024/11/12 20:13:11 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:13:11 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:13:11 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:13:11 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 15 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:13:44 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 7'].\n",
      "2024/11/12 20:13:44 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:13:44 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:13:44 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:13:44 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 16 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:14:19 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 10', 'Predictor 0: Few-Shot Set 5'].\n",
      "2024/11/12 20:14:19 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:14:19 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:14:19 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:14:19 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 17 / 25 =====\n",
      "  0%|          | 0/15 [01:08<?, ?it/s]\n",
      "  0%|          | 0/15 [00:34<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.25 / 1  (25.0):   7%|▋         | 1/15 [00:10<02:22, 10.20s/it]2024/11/12 20:14:47 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 13', 'Predictor 0: Few-Shot Set 10'].\n",
      "2024/11/12 20:14:47 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:14:47 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:14:47 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:14:47 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 18 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 11'].\n",
      "2024/11/12 20:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 19 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:16:08 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 10', 'Predictor 0: Few-Shot Set 7'].\n",
      "2024/11/12 20:16:08 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:16:08 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:16:08 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:16:08 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 20 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [01:20<?, ?it/s]\n",
      "  0%|          | 0/15 [00:38<?, ?it/s]\n",
      "2024/11/12 20:16:48 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 9', 'Predictor 0: Few-Shot Set 6'].\n",
      "2024/11/12 20:16:48 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:16:48 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:16:48 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:16:48 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 21 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:17:19 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 16', 'Predictor 0: Few-Shot Set 15'].\n",
      "2024/11/12 20:17:19 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:17:19 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:17:19 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:17:19 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 22 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:17:55 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 8'].\n",
      "2024/11/12 20:17:55 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:17:55 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:17:55 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:17:55 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 23 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:18:24 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 18'].\n",
      "2024/11/12 20:18:24 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:18:24 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:18:24 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:18:24 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 24 / 25 =====\n",
      "  0%|          | 0/15 [01:35<?, ?it/s]\n",
      "  0%|          | 0/15 [01:04<?, ?it/s]\n",
      "  0%|          | 0/15 [00:28<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:19:00 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 16'].\n",
      "2024/11/12 20:19:00 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:19:00 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:19:00 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:19:00 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 25 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]2024/11/12 20:19:41 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 18'].\n",
      "2024/11/12 20:19:41 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [21.82, 57.59, 69.31, 46.68, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2024/11/12 20:19:41 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 69.31\n",
      "2024/11/12 20:19:41 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2024/11/12 20:19:41 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 69.31!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    }
   ],
   "source": [
    "metric = SemanticF1()\n",
    "tp = dspy.MIPROv2(metric=metric, auto=\"medium\", num_threads=24)  # use fewer threads if your rate limit is small\n",
    "\n",
    "optimized_rag = tp.compile(\n",
    "    RAG(), \n",
    "    trainset=trainset, \n",
    "    valset=valset,\n",
    "\tmax_bootstrapped_demos=2,\n",
    " \tmax_labeled_demos=2,\n",
    "  \trequires_permission_to_run=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_rag.save(\"optimized_rag_v2.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
