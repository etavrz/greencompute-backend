{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dspy\n",
    "from dspy.evaluate import SemanticF1\n",
    "import json\n",
    "import requests\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to setup datset and evaluation\n",
    "def create_dataset(path: str) -> list[dspy.Example]:\n",
    "\tdataset = pd.read_excel(path)\n",
    "\tdataset_dict = dataset.to_dict(orient='records')\n",
    "\tdspy_dataset = []\n",
    "\n",
    "\tfor row in dataset_dict:\n",
    "\t\tdspy_dataset.append(dspy.Example(question=row['input'], response=row['expected_output']).with_inputs(\"question\"))\n",
    "\n",
    "\tprint(f\"Dataset length: {len(dspy_dataset)}\")\n",
    "\treturn dspy_dataset\n",
    "\n",
    "def create_sets(dataset: list[dspy.Example], metric: dspy.Module = SemanticF1()):\n",
    "\ttrainset, valset, devset, testset = dataset[:15], dataset[15:30], dataset[30:40], dataset[40:]\n",
    "\tevaluate = dspy.Evaluate(devset=devset, metric=metric, num_threads=24, display_progress=True, display_table=3)\n",
    "\n",
    "\tfor name, set in zip([trainset, valset, devset, testset], [\"trainset\", \"valset\", \"devset\", \"testset\"]):\n",
    "\t\tprint(f\"{set} length: {len(name)}\")\n",
    "\n",
    "\treturn trainset, valset, devset, testset, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 52\n",
      "trainset length: 15\n",
      "valset length: 15\n",
      "devset length: 10\n",
      "testset length: 12\n"
     ]
    }
   ],
   "source": [
    "dspy_dataset = create_dataset(\"synthetics/synthetic_dataset_revised.xlsx\")\n",
    "trainset, valset, devset, testset, evaluate = create_sets(dspy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, top_k: int) -> list[str]:\n",
    "    url = \"http://localhost:8000/api/llm/retrieval\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"query\": query,\n",
    "        \"top_k\": top_k\n",
    "    }\n",
    "\n",
    "    documents = requests.post(url, headers=headers, json=data).json()[\"documents\"]\n",
    "    return [f\"[{i}]\" + doc[\"doc_title\"] + doc[\"url\"] + \"\\n\\n\" + doc[\"content\"] for i, doc in enumerate(documents)]\n",
    "\n",
    "class TitanLM(dspy.LM):\n",
    "    def __init__(self, model: str, client, max_tokens: int = 1024, temperature: float = 0.7, top_p: float = 0.9, **kwargs):\n",
    "        self.client = client\n",
    "        self.history = []\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = 1024\n",
    "        self.top_p = top_p\n",
    "\n",
    "        super().__init__(model, **kwargs)\n",
    "        self.model = model\n",
    "    \n",
    "    def _format_message(self, prompt: str):\n",
    "        body = json.dumps(\n",
    "            {\n",
    "                \"inputText\": prompt,\n",
    "                \"textGenerationConfig\": {\n",
    "                    \"maxTokenCount\": self.max_tokens,\n",
    "                    \"stopSequences\": [],\n",
    "                    \"temperature\": self.temperature,\n",
    "                    \"topP\": self.top_p,\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "        return body\n",
    "\n",
    "    def generate_content(self, prompt: str) -> str:\n",
    "        body = self._format_message(prompt)\n",
    "        response = self.client.invoke_model(\n",
    "            body=body,\n",
    "            modelId=self.model,\n",
    "            accept=\"application/json\",\n",
    "            contentType=\"application/json\",\n",
    "        )\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "        return response_body.get(\"results\")\n",
    "\n",
    "    def __call__(self, prompt=None, messages=None, **kwargs):\n",
    "        # Custom chat model working for text completion model\n",
    "        prompt = '\\n\\n'.join([x['content'] for x in messages] + ['BEGIN RESPONSE:'])\n",
    "\n",
    "        completions = self.generate_content(prompt)\n",
    "        self.history.append({\"prompt\": prompt, \"completions\": completions})\n",
    "\n",
    "        # Must return a list of strings\n",
    "        return [completions[0].get(\"outputText\")]\n",
    "\n",
    "    def inspect_history(self):\n",
    "        for interaction in self.history:\n",
    "            print(f\"Prompt: {interaction['prompt']} -> Completions: {interaction['completions']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateCitedParagraph(dspy.Signature):\n",
    "    \"\"\"Generate a paragraph with citations.\"\"\"\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    paragraph = dspy.OutputField(desc=\"includes citations with links\")\n",
    "\n",
    "class CitedRAG(dspy.Module):\n",
    "    def __init__(self, num_docs=20):\n",
    "        self.num_docs = num_docs\n",
    "        self.respond = dspy.ChainOfThought(GenerateCitedParagraph)\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = search(question, top_k=self.num_docs)\n",
    "        return self.respond(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = TitanLM(\"amazon.titan-text-premier-v1:0\", client=boto3.client(\"bedrock-runtime\"))\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='To increase data center efficiency, consider implementing the following strategies:\\n1. Utilize energy-efficient servers and equipment, such as EPEAT-registered servers, which meet stricter performance requirements and criteria than ENERGY STAR.\\n2. Implement energy-efficient cooling solutions, such as computer room air conditioners (CRAC) or computer room air handlers (CRAH) with high supply air temperature capabilities.\\n3. Optimize power usage effectiveness (PUE) by minimizing energy consumption in non-IT infrastructure components, such as cooling and lighting systems.\\n4. Monitor and meter energy usage to identify areas for improvement and track progress towards energy efficiency goals.',\n",
       "    paragraph='To increase data center efficiency, consider the following strategies:\\n1. Utilize energy-efficient servers and equipment, such as EPEAT-registered servers, which meet stricter performance requirements and criteria than ENERGY STAR ([19]).\\n2. Implement energy-efficient cooling solutions, such as computer room air conditioners (CRAC) or computer room air handlers (CRAH) with high supply air temperature capabilities ([10]).\\n3. Optimize power usage effectiveness (PUE) by minimizing energy consumption in non-IT infrastructure components, such as cooling and lighting systems ([1]).\\n4. Monitor and meter energy usage to identify areas for improvement and track progress towards energy efficiency goals ([16]).'\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag = CitedRAG()\n",
    "rag(question=\"How do I increase my data center efficiency?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
